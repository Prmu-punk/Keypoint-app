#!/usr/bin/env python3
"""
å‚æ•°å˜æ¢å·¥å…·å‡½æ•°
ç”¨äºå°†åŸå§‹ä¼˜åŒ–å‚æ•°è½¬æ¢ä¸ºæœ€ç»ˆçš„å˜æ¢åå‚æ•°
"""

import json
import numpy as np
import torch
from scipy.spatial.transform import Rotation
import open3d as o3d
import os

def compute_combined_transform(incam_params, global_params):
    """
    è®¡ç®—ç»„åˆçš„å˜æ¢çŸ©é˜µï¼Œå°†transform_to_globalçš„å˜æ¢æ•´åˆä¸ºä¸€ä¸ªRå’ŒT
    :param incam_params: ç›¸æœºå†…å‚æ•° (incam_orient, incam_trans)
    :param global_params: å…¨å±€å‚æ•° (global_orient, global_trans)
    :return: ç»„åˆçš„æ—‹è½¬çŸ©é˜µRå’Œå¹³ç§»å‘é‡T
    """
    incam_orient, incam_trans = incam_params
    global_orient, global_trans = global_params
    
    # ç¬¬ä¸€æ­¥å˜æ¢ï¼šincam to original
    axis_angle = incam_orient.detach().cpu().numpy()
    R_2ori = Rotation.from_rotvec(axis_angle).as_matrix()
    T_2ori = incam_trans.detach().cpu().numpy().squeeze()
    T_2ori[1] -= 0.7
    T_2ori[0] += 0.13
    
    # ç¬¬äºŒæ­¥å˜æ¢ï¼šoriginal to global
    axis_angle = global_orient.cpu().numpy()
    global_R = Rotation.from_rotvec(axis_angle).as_matrix()
    global_T = global_trans.cpu().numpy()
    global_T[0] -= 0.12
    global_T[1] -= 0.01
    global_T[2] += 0.03
    
    # ç»„åˆå˜æ¢ï¼šå…ˆåº”ç”¨ incam->ori å˜æ¢ï¼Œå†åº”ç”¨ ori->global å˜æ¢
    # å¯¹äºæ—‹è½¬ï¼šR_combined = global_R @ R_2ori.T
    R_combined = global_R @ R_2ori.T
    
    # å¯¹äºå¹³ç§»ï¼šT_combined = global_R @ (-R_2ori.T @ T_2ori) + global_T
    T_combined = global_R @ (-R_2ori.T @ T_2ori) + global_T
    
    return R_combined, T_combined

def apply_transform_to_smpl_params(global_orient, transl, incam_params, global_params):
    """
    å°†transform_to_globalçš„å˜æ¢ç›´æ¥åº”ç”¨åˆ°SMPLå‚æ•°ä¸Š
    :param global_orient: åŸå§‹global_orient
    :param transl: åŸå§‹transl
    :param incam_params: ç›¸æœºå†…å‚æ•°
    :param global_params: å…¨å±€å‚æ•°
    :return: å˜æ¢åçš„global_orientå’Œtransl
    """
    R_combined, T_combined = compute_combined_transform(incam_params, global_params)
    
    # å°†ç»„åˆå˜æ¢åº”ç”¨åˆ°SMPLå‚æ•°
    # å¯¹äºglobal_orientï¼šéœ€è¦å°†æ—‹è½¬ç»„åˆ
    original_orient = global_orient.cpu().numpy()
    original_R = Rotation.from_rotvec(original_orient).as_matrix()
    new_R = R_combined @ original_R
    new_orient = Rotation.from_matrix(new_R).as_rotvec()
    
    # å¯¹äºtranslï¼šåº”ç”¨ç»„åˆå˜æ¢
    original_transl = transl.cpu().numpy()
    if original_transl.ndim > 1:
        original_transl = original_transl.squeeze()
    new_transl = R_combined @ original_transl + T_combined
    
    return new_orient, new_transl

def transform_and_save_parameters(human_params_dict, org_params, camera_params, output_dir, original_object_path, user_scale=1.0):
    """
    å˜æ¢å¹¶ä¿å­˜å‚æ•°
    :param human_params_dict: äººä½“å‚æ•°å­—å…¸ {"body_pose": {...}, "global_orient": {...}, ...}
    :param org_params: åŸå§‹ç‰©ä½“å‚æ•° (self.object_poses)
    :param camera_params: ç›¸æœºå‚æ•° (self.output)  
    :param output_dir: è¾“å‡ºç›®å½•
    :param original_object_path: åŸå§‹ç‰©ä½“meshæ–‡ä»¶è·¯å¾„
    :param user_scale: ç”¨æˆ·è¾“å…¥çš„scaleå‚æ•°
    :return: ä¿å­˜æˆåŠŸçš„æ–‡ä»¶è·¯å¾„åˆ—è¡¨
    """
    print("ğŸ”„ Transforming and saving parameters...")
    
    # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
    os.makedirs(output_dir, exist_ok=True)
    
    # ä»ç›¸æœºå‚æ•°ä¸­æå–incamå’Œglobalå‚æ•°
    incam_params = camera_params["smpl_params_incam"]
    global_params = camera_params["smpl_params_global"]
    
    # å°†å­—ç¬¦ä¸²é”®è½¬æ¢ä¸ºæ•´æ•°å¹¶æ’åº
    sorted_frames = sorted([int(k) for k in human_params_dict['body_pose'].keys()])
    
    # å˜æ¢åçš„äººä½“å‚æ•°
    transformed_human_params = {
        'body_pose': {},
        'betas': {},
        'global_orient': {},
        'transl': {},
        'left_hand_pose': {},
        'right_hand_pose': {},
    }
    
    print(f"ğŸ“ Transforming human parameters for {len(sorted_frames)} frames...")
    
    for id, frame_idx in enumerate(sorted_frames):
        frame_str = str(frame_idx)
        
        # è·å–åŸå§‹å‚æ•°
        original_global_orient = torch.tensor(human_params_dict['global_orient'][frame_str], dtype=torch.float32)
        original_transl = torch.tensor(human_params_dict['transl'][frame_str], dtype=torch.float32)
        
        # è·å–ç›¸æœºå‚æ•°
        incam_param = (incam_params['global_orient'][id], incam_params['transl'][id])
        global_param = (global_params['global_orient'][id], global_params['transl'][id])
        
        # åº”ç”¨å˜æ¢åˆ°SMPLå‚æ•°
        new_global_orient, new_transl = apply_transform_to_smpl_params(
            original_global_orient, original_transl, incam_param, global_param
        )
        
        # ä¿å­˜å˜æ¢åçš„å‚æ•°
        transformed_human_params['body_pose'][frame_str] = human_params_dict['body_pose'][frame_str]
        transformed_human_params['betas'][frame_str] = human_params_dict['betas'][frame_str]
        transformed_human_params['global_orient'][frame_str] = new_global_orient.tolist()
        transformed_human_params['transl'][frame_str] = new_transl.tolist()
        transformed_human_params['left_hand_pose'][frame_str] = human_params_dict['left_hand_pose'][frame_str]
        transformed_human_params['right_hand_pose'][frame_str] = human_params_dict['right_hand_pose'][frame_str]
    
    # å¤„ç†ç‰©ä½“å‚æ•°ï¼ˆå¦‚æœå­˜åœ¨ç‰©ä½“ä¼˜åŒ–ç»“æœï¼‰
    transformed_object_params = None
    transformed_object_path = None
    
    if 'poses' in org_params and org_params['poses'] and original_object_path and os.path.exists(original_object_path):
        print("ğŸ“ Transforming object parameters and mesh...")
        
        # è·å–scaleå‚æ•°
        scale = org_params.get('scale', 1.0)
        scale_init = user_scale  # ç”¨æˆ·è¾“å…¥çš„scale
        
        transformed_object_params = {
            'R_total': {},  # æœ€ç»ˆæ—‹è½¬çŸ©é˜µ
            'T_total': {},  # æœ€ç»ˆå¹³ç§»å‘é‡
            'scale': scale,
            'scale_init': scale_init
        }
        
        for id, frame_idx in enumerate(sorted_frames):
            frame_str = str(frame_idx)
            
            if frame_idx < len(org_params['poses']) and org_params['poses'][frame_str] is not None:
                # è·å–åŸå§‹ç‰©ä½“å˜æ¢
                R_final = np.array(org_params['poses'][frame_str])
                t_final = np.array(org_params['centers'][frame_str])
                
                # è·å–ç›¸æœºå‚æ•°
                incam_param = (incam_params['global_orient'][id], incam_params['transl'][id])
                global_param = (global_params['global_orient'][id], global_params['transl'][id])
                
                # è®¡ç®—ç»„åˆå˜æ¢çŸ©é˜µ
                R_combined, T_combined = compute_combined_transform(incam_param, global_param)
                
                # è®¡ç®—æœ€ç»ˆå˜æ¢çŸ©é˜µ
                R_total = R_combined @ R_final
                T_total = R_combined @ t_final + T_combined
                
                # ä¿å­˜æœ€ç»ˆå˜æ¢
                transformed_object_params['R_total'][frame_str] = R_total.tolist()
                transformed_object_params['T_total'][frame_str] = T_total.tolist()
            else:
                # å¦‚æœæŸå¸§æ²¡æœ‰ç‰©ä½“å‚æ•°ï¼Œä½¿ç”¨å•ä½çŸ©é˜µå’Œé›¶å‘é‡
                transformed_object_params['R_total'][frame_str] = np.eye(3).tolist()
                transformed_object_params['T_total'][frame_str] = np.zeros(3).tolist()
        
        # å˜æ¢å¹¶ä¿å­˜ç‰©ä½“mesh
        transformed_object_path = transform_and_save_object_mesh(
            original_object_path, scale, scale_init, output_dir
        )
        
        print(f"âœ… Transformed object parameters with scale: {scale}, scale_init: {scale_init}")
    
    # ç”Ÿæˆæ—¶é—´æˆ³
    from datetime import datetime
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    
    # ä¿å­˜å˜æ¢åçš„å‚æ•°
    saved_files = []
    
    # ä¿å­˜å®Œæ•´çš„å˜æ¢åå‚æ•°
    transformed_data = {
        'metadata': {
            'description': 'Transformed parameters with all transforms applied',
            'total_frames': len(sorted_frames),
            'frame_indices': sorted_frames,
            'has_object_params': transformed_object_params is not None,
            'user_scale': user_scale
        },
        'human_params': transformed_human_params
    }
    
    if transformed_object_params is not None:
        transformed_data['object_params'] = transformed_object_params
    
    transformed_params_path = os.path.join(output_dir, f'transformed_parameters_{timestamp}.json')
    with open(transformed_params_path, 'w') as f:
        json.dump(transformed_data, f, indent=2)
    saved_files.append(transformed_params_path)
    print(f"âœ… Saved transformed parameters: {transformed_params_path}")
    
    # å¦‚æœæœ‰å˜æ¢åçš„ç‰©ä½“meshï¼Œæ·»åŠ åˆ°æ–‡ä»¶åˆ—è¡¨
    if transformed_object_path:
        saved_files.append(transformed_object_path)
    
    print(f"ğŸ‰ Successfully saved {len(saved_files)} files!")
    return saved_files

def transform_and_save_object_mesh(original_object_path, scale, scale_init, output_dir):
    """
    å¯¹ç‰©ä½“meshåº”ç”¨scaleå˜æ¢å¹¶ä¿å­˜æ–°çš„ç‰©ä½“mesh
    """
    print(f"ğŸ”„ Transforming object mesh: {original_object_path}")
    
    # åŠ è½½åŸå§‹ç‰©ä½“mesh
    original_mesh = o3d.io.read_triangle_mesh(original_object_path)
    if len(original_mesh.vertices) == 0:
        print(f"âŒ Error: Could not load mesh from {original_object_path}")
        return None
    
    original_vertices = np.asarray(original_mesh.vertices)
    
    # åº”ç”¨scaleå˜æ¢
    print(f"ğŸ“ Applying scale transformations: scale={scale}, scale_init={scale_init}")
    scaled_vertices = original_vertices * scale
    
    # ä¸­å¿ƒåŒ–å¹¶åº”ç”¨åˆå§‹scale
    center_m = np.mean(scaled_vertices, axis=0)
    scaled_vertices -= center_m  # ä¸­å¿ƒåŒ–é¡¶ç‚¹
    scaled_vertices *= scale_init  # æ¢å¤åˆå§‹scale
    
    # åˆ›å»ºæ–°çš„mesh
    transformed_mesh = o3d.geometry.TriangleMesh()
    transformed_mesh.vertices = o3d.utility.Vector3dVector(scaled_vertices)
    transformed_mesh.triangles = original_mesh.triangles
    
    # å¦‚æœåŸå§‹meshæœ‰é¢œè‰²ï¼Œä¿æŒé¢œè‰²
    if original_mesh.has_vertex_colors():
        transformed_mesh.vertex_colors = original_mesh.vertex_colors
    if original_mesh.has_vertex_normals():
        transformed_mesh.vertex_normals = original_mesh.vertex_normals
    
    # é‡æ–°è®¡ç®—æ³•å‘é‡
    transformed_mesh.compute_vertex_normals()
    
    # ç”Ÿæˆæ—¶é—´æˆ³å’Œè¾“å‡ºè·¯å¾„
    from datetime import datetime
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    output_object_path = os.path.join(output_dir, f'transformed_object_{timestamp}.obj')
    
    # ä¿å­˜å˜æ¢åçš„mesh
    success = o3d.io.write_triangle_mesh(output_object_path, transformed_mesh)
    
    if success:
        print(f"âœ… Transformed object mesh saved to: {output_object_path}")
        return output_object_path
    else:
        print(f"âŒ Error: Failed to save transformed mesh to: {output_object_path}")
        return None
